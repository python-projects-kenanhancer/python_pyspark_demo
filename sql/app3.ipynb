{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cab52f056c7a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:44.826575Z",
     "start_time": "2023-11-11T01:08:44.785109Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/10/14 23:17:47 WARN Utils: Your hostname, kenans-MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.102 instead (on interface en0)\n",
      "25/10/14 23:17:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/14 23:17:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/10/14 23:17:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/10/14 23:17:48 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/10/14 23:17:48 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "25/10/14 23:17:48 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "25/10/14 23:17:48 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485afd0ce172cee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:47.098145Z",
     "start_time": "2023-11-11T01:08:44.794523Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Alice|  2|\n",
      "|  Bob|  5|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], [\"age\", \"name\"])\n",
    "df.select(df.name, df.age).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765a0837c7cda3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:47.934748Z",
     "start_time": "2023-11-11T01:08:47.094809Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+\n",
      "| name|age|(age + 1)|\n",
      "+-----+---+---------+\n",
      "|Alice|  2|        3|\n",
      "|  Bob|  5|        6|\n",
      "+-----+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], [\"age\", \"name\"])\n",
    "df.select(df.name, df.age, df.age + 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f7df189db3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:48.560784Z",
     "start_time": "2023-11-11T01:08:47.931310Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "| name|age|agePlusOne|\n",
      "+-----+---+----------+\n",
      "|Alice|  2|         3|\n",
      "|  Bob|  5|         6|\n",
      "+-----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], [\"age\", \"name\"])\n",
    "df.select(df.name, df.age, (df.age + 1).alias(\"agePlusOne\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5391c5701d6e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:49.178514Z",
     "start_time": "2023-11-11T01:08:48.553736Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|agePlusOne|\n",
      "+----+---+----------+\n",
      "| Bob|  5|         6|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], [\"age\", \"name\"])\n",
    "df.select(df.name, df.age, (df.age + 1).alias(\"agePlusOne\")).filter(df.age > 3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7027109e726c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:49.691295Z",
     "start_time": "2023-11-11T01:08:49.175814Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob is 5 years old, and will be 6 years old next year\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], [\"age\", \"name\"])\n",
    "df_filtered = df.select(df.name, df.age, (df.age + 1).alias(\"agePlusOne\")).filter(df.age > 3).collect()\n",
    "\n",
    "for row in df_filtered:\n",
    "    print(f\"{row.name} is {row.age} years old, and will be {row.agePlusOne} years old next year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db59f067c0af6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:49.960109Z",
     "start_time": "2023-11-11T01:08:49.688867Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob is 5 years old, and will be 6 years old next year\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (2, \"Alice\"),\n",
    "        (5, \"Bob\"),\n",
    "    ],\n",
    "    [\n",
    "        \"age\",\n",
    "        \"name\",\n",
    "    ],\n",
    ")\n",
    "df_filtered = df.select(df.name, df.age, (df.age + 1).alias(\"agePlusOne\")).filter(df.age > 3).collect()\n",
    "rows = map(lambda r: f\"{r.name} is {r.age} years old, and will be {r.agePlusOne} years old next year\", df_filtered)\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98205f96b0712444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:50.258727Z",
     "start_time": "2023-11-11T01:08:49.957778Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Bob', 'age': 5, 'agePlusOne': 6}\n",
      "Bob is 5 years old, and will be 6 years old next year\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (2, \"Alice\"),\n",
    "        (5, \"Bob\"),\n",
    "    ],\n",
    "    [\"age\", \"name\"],\n",
    ")\n",
    "df_filtered = df.select(df.name, df.age, (df.age + 1).alias(\"agePlusOne\")).filter(df.age > 3).collect()\n",
    "rows_dict = map(lambda r: r.asDict(), df_filtered)\n",
    "\n",
    "for row in rows_dict:\n",
    "    print(row)\n",
    "    print(f\"{row['name']} is {row['age']} years old, and will be {row['agePlusOne']} years old next year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac156ab29a32961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:50.509510Z",
     "start_time": "2023-11-11T01:08:50.256121Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob is 5 years old, and will be 6 years old next year\n"
     ]
    }
   ],
   "source": [
    "def print_person_details(person):\n",
    "    return f\"{person.name} is {person.age} years old, and will be {person.agePlusOne} years old next year\"\n",
    "\n",
    "\n",
    "df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], [\"age\", \"name\"])\n",
    "df_filtered = df.select(df.name, df.age, (df.age + 1).alias(\"agePlusOne\")).filter(df.age > 3).collect()\n",
    "rows = map(lambda r: print_person_details(r), df_filtered)\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad58a291a884425",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:09:32.212231Z",
     "start_time": "2023-11-11T01:09:32.003639Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Bob', 'age': 5, 'agePlusOne': 6}\n",
      "Bob is 5 years old, and will be 6 years old next year\n"
     ]
    }
   ],
   "source": [
    "def print_person_details(person):\n",
    "    return f\"{person['name']} is {person['age']} years old, and will be {person['agePlusOne']} years old next year\"\n",
    "\n",
    "\n",
    "df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], [\"age\", \"name\"])\n",
    "df_filtered = df.select(df.name, df.age, (col(\"age\") + 1).alias(\"agePlusOne\")).filter(col(\"age\") > 3).collect()\n",
    "\n",
    "rows = map(lambda r: r.asDict(), df_filtered)\n",
    "\n",
    "for row in rows:\n",
    "    print(row)\n",
    "    print(print_person_details(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de744bd714bfe47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:51.786921Z",
     "start_time": "2023-11-11T01:08:50.781010Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "|age| name|agePlusOne|\n",
      "+---+-----+----------+\n",
      "|  2|Alice|         3|\n",
      "|  5|  Bob|         6|\n",
      "+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (2, \"Alice\"),\n",
    "        (5, \"Bob\"),\n",
    "    ],\n",
    "    [\"age\", \"name\"],\n",
    ")\n",
    "\n",
    "age_plus_one_udf = udf(lambda age: age + 1, IntegerType())\n",
    "\n",
    "df.withColumn(\"agePlusOne\", age_plus_one_udf(df.age)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839229214bd5634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:53.300099Z",
     "start_time": "2023-11-11T01:08:51.784289Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|agePlusOne|\n",
      "+----+---+----------+\n",
      "| Bob|  5|         6|\n",
      "+----+---+----------+\n",
      "\n",
      "+---+----+----------+\n",
      "|age|name|agePlusOne|\n",
      "+---+----+----------+\n",
      "|  5| Bob|         6|\n",
      "+---+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (2, \"Alice\"),\n",
    "        (5, \"Bob\"),\n",
    "    ],\n",
    "    [\"age\", \"name\"],\n",
    ")\n",
    "\n",
    "age_plus_one_udf = udf(lambda age: age + 1, IntegerType())\n",
    "\n",
    "# V1\n",
    "df.select(df.name, df.age, age_plus_one_udf(df.age).alias(\"agePlusOne\")).filter(df.age > 3).show()\n",
    "\n",
    "# V2\n",
    "df.filter(df.age > 3).withColumn(\"agePlusOne\", age_plus_one_udf(df.age)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d995e9c7a6817a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:53.711499Z",
     "start_time": "2023-11-11T01:08:53.297624Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 5, 'name': 'Bob', 'agePlusOne': 6}\n",
      "Bob is 5 years old, and will be 6 years old next year\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], [\"age\", \"name\"])\n",
    "\n",
    "age_plus_one_udf = udf(lambda age: age + 1, IntegerType())\n",
    "\n",
    "df_filtered = df.withColumn(\"agePlusOne\", age_plus_one_udf(df.age)).filter(df.age > 3).collect()\n",
    "\n",
    "rows = [row.asDict() for row in df_filtered]\n",
    "\n",
    "for row in rows:\n",
    "    print(row)\n",
    "    print(f\"{row['name']} is {row['age']} years old, and will be {row['agePlusOne']} years old next year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146897aa1db139a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T01:08:54.047489Z",
     "start_time": "2023-11-11T01:08:53.711183Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 5, 'name': 'Bob', 'agePlusOne': 6}\n",
      "Bob is 5 years old, and will be 6 years old next year\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], [\"age\", \"name\"])\n",
    "\n",
    "age_plus_one_udf = udf(lambda age: age + 1, IntegerType())\n",
    "\n",
    "df_filtered = df.withColumn(\"agePlusOne\", age_plus_one_udf(col(\"age\"))).filter(col(\"age\") > 3).collect()\n",
    "\n",
    "rows = [row.asDict() for row in df_filtered]\n",
    "\n",
    "for row in rows:\n",
    "    print(row)\n",
    "    print(f\"{row['name']} is {row['age']} years old, and will be {row['agePlusOne']} years old next year\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
