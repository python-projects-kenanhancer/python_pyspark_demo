{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create sample DataFrames for demonstration\n",
    "print(\"=== SAMPLE DATA CREATION ===\")\n",
    "\n",
    "# Employee DataFrame\n",
    "employees = pd.DataFrame(\n",
    "    {\n",
    "        \"emp_id\": [\"E001\", \"E002\", \"E003\", \"E004\", \"E005\"],\n",
    "        \"name\": [\"Alice\", \"Bob\", \"Carol\", \"David\", \"Eve\"],\n",
    "        \"department\": [\"Engineering\", \"Marketing\", \"Engineering\", \"Sales\", \"Marketing\"],\n",
    "        \"salary\": [75000, 65000, 80000, 55000, 70000],\n",
    "        \"manager_id\": [\"M001\", \"M002\", \"M001\", \"M003\", \"M002\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Manager DataFrame\n",
    "managers = pd.DataFrame(\n",
    "    {\n",
    "        \"manager_id\": [\"M001\", \"M002\", \"M003\"],\n",
    "        \"manager_name\": [\"John\", \"Sarah\", \"Mike\"],\n",
    "        \"department\": [\"Engineering\", \"Marketing\", \"Sales\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Department DataFrame\n",
    "departments = pd.DataFrame(\n",
    "    {\n",
    "        \"dept_name\": [\"Engineering\", \"Marketing\", \"Sales\", \"HR\"],\n",
    "        \"budget\": [500000, 300000, 250000, 150000],\n",
    "        \"location\": [\"Building A\", \"Building B\", \"Building C\", \"Building D\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Employees DataFrame:\")\n",
    "print(employees)\n",
    "print(\"\\nManagers DataFrame:\")\n",
    "print(managers)\n",
    "print(\"\\nDepartments DataFrame:\")\n",
    "print(departments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e223b20",
   "metadata": {},
   "source": [
    "## 1. MERGING DataFrames\n",
    "\n",
    "Merging combines DataFrames based on common columns (like SQL JOINs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MERGING OPERATIONS ===\")\n",
    "\n",
    "# 1. INNER JOIN - Only matching records\n",
    "print(\"1. INNER JOIN (employees + managers):\")\n",
    "inner_merge = pd.merge(employees, managers, on=\"manager_id\", how=\"inner\")\n",
    "print(inner_merge)\n",
    "\n",
    "# 2. LEFT JOIN - All employees, matching managers where available\n",
    "print(\"\\n2. LEFT JOIN (employees + managers):\")\n",
    "left_merge = pd.merge(employees, managers, on=\"manager_id\", how=\"left\")\n",
    "print(left_merge)\n",
    "\n",
    "# 3. RIGHT JOIN - All managers, matching employees where available\n",
    "print(\"\\n3. RIGHT JOIN (employees + managers):\")\n",
    "right_merge = pd.merge(employees, managers, on=\"manager_id\", how=\"right\")\n",
    "print(right_merge)\n",
    "\n",
    "# 4. OUTER JOIN - All records from both DataFrames\n",
    "print(\"\\n4. OUTER JOIN (employees + managers):\")\n",
    "outer_merge = pd.merge(employees, managers, on=\"manager_id\", how=\"outer\")\n",
    "print(outer_merge)\n",
    "\n",
    "# 5. Merge on different column names\n",
    "print(\"\\n5. MERGE on different column names (employees.department = departments.dept_name):\")\n",
    "dept_merge = pd.merge(employees, departments, left_on=\"department\", right_on=\"dept_name\", how=\"left\")\n",
    "print(dept_merge)\n",
    "\n",
    "# 6. Multiple column merge\n",
    "print(\"\\n6. MERGE on multiple columns:\")\n",
    "multi_merge = pd.merge(employees, managers, on=[\"manager_id\", \"department\"], how=\"inner\")\n",
    "print(multi_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc3aa5",
   "metadata": {},
   "source": [
    "## 2. COMBINING DataFrames\n",
    "\n",
    "Combining DataFrames by concatenating rows or columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== COMBINING OPERATIONS ===\")\n",
    "\n",
    "# Create additional DataFrames for combining\n",
    "new_employees = pd.DataFrame(\n",
    "    {\n",
    "        \"emp_id\": [\"E006\", \"E007\"],\n",
    "        \"name\": [\"Frank\", \"Grace\"],\n",
    "        \"department\": [\"HR\", \"Engineering\"],\n",
    "        \"salary\": [60000, 85000],\n",
    "        \"manager_id\": [\"M004\", \"M001\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# 1. CONCATENATE ROWS (pd.concat with axis=0)\n",
    "print(\"1. CONCATENATE ROWS (add new employees):\")\n",
    "combined_employees = pd.concat([employees, new_employees], axis=0, ignore_index=True)\n",
    "print(combined_employees)\n",
    "\n",
    "# 2. CONCATENATE COLUMNS (pd.concat with axis=1)\n",
    "print(\"\\n2. CONCATENATE COLUMNS:\")\n",
    "# Create additional info DataFrame\n",
    "additional_info = pd.DataFrame(\n",
    "    {\n",
    "        \"emp_id\": [\"E001\", \"E002\", \"E003\", \"E004\", \"E005\"],\n",
    "        \"hire_date\": [\"2020-01-15\", \"2019-03-22\", \"2021-06-10\", \"2018-11-05\", \"2020-09-18\"],\n",
    "        \"bonus\": [5000, 3000, 6000, 2000, 4000],\n",
    "    }\n",
    ")\n",
    "\n",
    "combined_cols = pd.concat([employees, additional_info], axis=1)\n",
    "print(combined_cols)\n",
    "\n",
    "# 3. APPEND (deprecated - use pd.concat instead)\n",
    "print(\"\\n3. APPEND (deprecated - use pd.concat instead):\")\n",
    "appended = pd.concat([employees, new_employees], axis=0, ignore_index=True)\n",
    "print(appended)\n",
    "\n",
    "# 4. JOIN DataFrames (different from merge)\n",
    "print(\"\\n4. JOIN DataFrames (index-based):\")\n",
    "employees_indexed = employees.set_index(\"emp_id\")\n",
    "managers_indexed = managers.set_index(\"manager_id\")\n",
    "joined = employees_indexed.join(managers_indexed, on=\"manager_id\", how=\"left\")\n",
    "print(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5470e84",
   "metadata": {},
   "source": [
    "## 3. GROUPING DataFrames\n",
    "\n",
    "Grouping allows you to perform operations on subsets of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== GROUPING OPERATIONS ===\")\n",
    "\n",
    "# 1. BASIC GROUPBY with single aggregation\n",
    "print(\"1. GROUP BY department - average salary:\")\n",
    "dept_avg_salary = employees.groupby(\"department\")[\"salary\"].mean()\n",
    "print(dept_avg_salary)\n",
    "\n",
    "# 2. GROUPBY with multiple aggregations\n",
    "print(\"\\n2. GROUP BY department - multiple statistics:\")\n",
    "dept_stats = employees.groupby(\"department\")[\"salary\"].agg([\"count\", \"mean\", \"min\", \"max\", \"sum\"])\n",
    "print(dept_stats)\n",
    "\n",
    "# 3. GROUPBY with custom aggregation functions\n",
    "print(\"\\n3. GROUP BY department - custom aggregations:\")\n",
    "dept_custom = employees.groupby(\"department\").agg(\n",
    "    {\n",
    "        \"salary\": [\"mean\", \"std\", \"count\"],\n",
    "        \"name\": \"count\",  # Count of employees\n",
    "    }\n",
    ")\n",
    "print(dept_custom)\n",
    "\n",
    "# 4. GROUPBY with multiple columns\n",
    "print(\"\\n4. GROUP BY department and manager_id:\")\n",
    "dept_manager = (\n",
    "    employees.groupby([\"department\", \"manager_id\"])\n",
    "    .agg({\"salary\": \"sum\", \"name\": \"count\"})\n",
    "    .rename(columns={\"name\": \"employee_count\"})\n",
    ")\n",
    "print(dept_manager)\n",
    "\n",
    "# 5. GROUPBY with transform (keep original shape)\n",
    "print(\"\\n5. GROUP BY with transform (add department average to each row):\")\n",
    "employees[\"dept_avg_salary\"] = employees.groupby(\"department\")[\"salary\"].transform(\"mean\")\n",
    "print(employees)\n",
    "\n",
    "# 6. GROUPBY with filter\n",
    "print(\"\\n6. GROUP BY with filter (departments with more than 1 employee):\")\n",
    "filtered_depts = employees.groupby(\"department\").filter(lambda x: len(x) > 1)\n",
    "print(filtered_depts)\n",
    "\n",
    "# 7. GROUPBY with apply (custom function)\n",
    "print(\"\\n7. GROUP BY with apply (custom function):\")\n",
    "\n",
    "\n",
    "def top_earner(group):\n",
    "    return group.nlargest(1, \"salary\")\n",
    "\n",
    "\n",
    "top_earners = employees.groupby(\"department\").apply(top_earner)\n",
    "print(top_earners)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7953fa",
   "metadata": {},
   "source": [
    "## 4. FILTERING DataFrames\n",
    "\n",
    "Advanced filtering techniques beyond basic boolean indexing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FILTERING OPERATIONS ===\")\n",
    "\n",
    "# 1. BASIC FILTERING (boolean indexing)\n",
    "print(\"1. Basic filtering - high earners:\")\n",
    "high_earners = employees[employees[\"salary\"] > 70000]\n",
    "print(high_earners)\n",
    "\n",
    "# 2. MULTIPLE CONDITIONS\n",
    "print(\"\\n2. Multiple conditions - Engineering high earners:\")\n",
    "eng_high = employees[(employees[\"department\"] == \"Engineering\") & (employees[\"salary\"] > 70000)]\n",
    "print(eng_high)\n",
    "\n",
    "# 3. ISIN() for multiple values\n",
    "print(\"\\n3. ISIN() - employees in specific departments:\")\n",
    "target_depts = employees[employees[\"department\"].isin([\"Engineering\", \"Marketing\"])]\n",
    "print(target_depts)\n",
    "\n",
    "# 4. QUERY() method\n",
    "print(\"\\n4. QUERY() method - readable filtering:\")\n",
    "query_result = employees.query(\"salary > 70000 and department in ['Engineering', 'Marketing']\")\n",
    "print(query_result)\n",
    "\n",
    "# 5. STRING FILTERING\n",
    "print(\"\\n5. String filtering - names starting with 'A':\")\n",
    "a_names = employees[employees[\"name\"].str.startswith(\"A\")]\n",
    "print(a_names)\n",
    "\n",
    "# 6. REGEX FILTERING\n",
    "print(\"\\n6. Regex filtering - names containing 'a' or 'e':\")\n",
    "regex_names = employees[employees[\"name\"].str.contains(\"[ae]\", regex=True)]\n",
    "print(regex_names)\n",
    "\n",
    "# 7. NULL/NAN FILTERING\n",
    "print(\"\\n7. Null filtering (if we had nulls):\")\n",
    "# Create DataFrame with nulls for demonstration\n",
    "employees_with_nulls = employees.copy()\n",
    "employees_with_nulls.loc[1, \"salary\"] = np.nan\n",
    "print(\"Original with nulls:\")\n",
    "print(employees_with_nulls)\n",
    "print(\"\\nNon-null salaries:\")\n",
    "non_null = employees_with_nulls[employees_with_nulls[\"salary\"].notna()]\n",
    "print(non_null)\n",
    "\n",
    "# 8. BETWEEN FILTERING\n",
    "print(\"\\n8. BETWEEN filtering - salary range:\")\n",
    "salary_range = employees[employees[\"salary\"].between(60000, 80000)]\n",
    "print(salary_range)\n",
    "\n",
    "# 9. NTH LARGEST/SMALLEST\n",
    "print(\"\\n9. NTH largest - top 2 earners:\")\n",
    "top_2 = employees.nlargest(2, \"salary\")\n",
    "print(top_2)\n",
    "\n",
    "# 10. SAMPLE FILTERING\n",
    "print(\"\\n10. Random sampling - 3 random employees:\")\n",
    "sample = employees.sample(n=3, random_state=42)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a18440e",
   "metadata": {},
   "source": [
    "## 5. PIVOTING and RESHAPING DataFrames\n",
    "\n",
    "Transforming data structure for different analysis needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdef584",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PIVOTING and RESHAPING OPERATIONS ===\")\n",
    "\n",
    "# Create sample data for pivoting\n",
    "sales_data = pd.DataFrame(\n",
    "    {\n",
    "        \"date\": [\"2023-01-01\", \"2023-01-01\", \"2023-01-02\", \"2023-01-02\", \"2023-01-03\", \"2023-01-03\"],\n",
    "        \"product\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n",
    "        \"sales\": [100, 150, 120, 180, 110, 160],\n",
    "        \"region\": [\"North\", \"South\", \"North\", \"South\", \"North\", \"South\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Original sales data:\")\n",
    "print(sales_data)\n",
    "\n",
    "# 1. PIVOT TABLE\n",
    "print(\"\\n1. PIVOT TABLE - products as columns:\")\n",
    "pivot_sales = sales_data.pivot_table(index=\"date\", columns=\"product\", values=\"sales\", aggfunc=\"sum\")\n",
    "print(pivot_sales)\n",
    "\n",
    "# 2. PIVOT TABLE with multiple aggregations\n",
    "print(\"\\n2. PIVOT TABLE with multiple aggregations:\")\n",
    "pivot_multi = sales_data.pivot_table(index=\"region\", columns=\"product\", values=\"sales\", aggfunc=[\"sum\", \"mean\", \"count\"])\n",
    "print(pivot_multi)\n",
    "\n",
    "# 3. MELT (unpivot)\n",
    "print(\"\\n3. MELT (unpivot) - convert columns to rows:\")\n",
    "melted = pivot_sales.melt(id_vars=None, value_vars=[\"A\", \"B\"], var_name=\"product\", value_name=\"sales\").reset_index()\n",
    "print(melted)\n",
    "\n",
    "# 4. STACK and UNSTACK\n",
    "print(\"\\n4. STACK and UNSTACK:\")\n",
    "# First create a multi-index DataFrame\n",
    "multi_index_df = sales_data.set_index([\"date\", \"product\"])\n",
    "print(\"Multi-index DataFrame:\")\n",
    "print(multi_index_df)\n",
    "\n",
    "# Stack (convert columns to index)\n",
    "stacked = multi_index_df.stack()\n",
    "print(\"\\nStacked:\")\n",
    "print(stacked)\n",
    "\n",
    "# Unstack (convert index to columns)\n",
    "unstacked = stacked.unstack()\n",
    "print(\"\\nUnstacked:\")\n",
    "print(unstacked)\n",
    "\n",
    "# 5. WIDE to LONG format\n",
    "print(\"\\n5. WIDE to LONG format:\")\n",
    "wide_data = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": [1, 2, 3],\n",
    "        \"name\": [\"Alice\", \"Bob\", \"Carol\"],\n",
    "        \"math_score\": [85, 90, 78],\n",
    "        \"english_score\": [92, 88, 85],\n",
    "        \"science_score\": [78, 95, 82],\n",
    "    }\n",
    ")\n",
    "print(\"Wide format:\")\n",
    "print(wide_data)\n",
    "\n",
    "long_data = pd.melt(\n",
    "    wide_data,\n",
    "    id_vars=[\"id\", \"name\"],\n",
    "    value_vars=[\"math_score\", \"english_score\", \"science_score\"],\n",
    "    var_name=\"subject\",\n",
    "    value_name=\"score\",\n",
    ")\n",
    "print(\"\\nLong format:\")\n",
    "print(long_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc54f9e",
   "metadata": {},
   "source": [
    "## 6. ADVANCED OPERATIONS\n",
    "\n",
    "More sophisticated DataFrame manipulations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db738328",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ADVANCED OPERATIONS ===\")\n",
    "\n",
    "# 1. WINDOW FUNCTIONS (using rolling, expanding)\n",
    "print(\"1. WINDOW FUNCTIONS - rolling averages:\")\n",
    "# Create time series data\n",
    "dates = pd.date_range(\"2023-01-01\", periods=10, freq=\"D\")\n",
    "ts_data = pd.DataFrame({\"date\": dates, \"value\": np.random.randint(50, 100, 10)})\n",
    "print(\"Time series data:\")\n",
    "print(ts_data)\n",
    "\n",
    "# Rolling window\n",
    "ts_data[\"rolling_3\"] = ts_data[\"value\"].rolling(window=3).mean()\n",
    "ts_data[\"rolling_5\"] = ts_data[\"value\"].rolling(window=5).mean()\n",
    "print(\"\\nWith rolling averages:\")\n",
    "print(ts_data)\n",
    "\n",
    "# 2. RANKING\n",
    "print(\"\\n2. RANKING operations:\")\n",
    "employees[\"salary_rank\"] = employees[\"salary\"].rank(ascending=False)\n",
    "employees[\"salary_percentile\"] = employees[\"salary\"].rank(pct=True)\n",
    "print(employees[[\"name\", \"salary\", \"salary_rank\", \"salary_percentile\"]])\n",
    "\n",
    "# 3. CUT and Q-CUT (binning)\n",
    "print(\"\\n3. BINNING with cut and qcut:\")\n",
    "employees[\"salary_bins\"] = pd.cut(employees[\"salary\"], bins=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
    "employees[\"salary_quartiles\"] = pd.qcut(employees[\"salary\"], q=4, labels=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"])\n",
    "print(employees[[\"name\", \"salary\", \"salary_bins\", \"salary_quartiles\"]])\n",
    "\n",
    "# 4. CROSS TABULATION\n",
    "print(\"\\n4. CROSS TABULATION:\")\n",
    "# Create categorical data\n",
    "employees[\"performance\"] = [\"High\", \"Medium\", \"High\", \"Low\", \"Medium\"]\n",
    "crosstab = pd.crosstab(employees[\"department\"], employees[\"performance\"], margins=True)\n",
    "print(crosstab)\n",
    "\n",
    "# 5. DUPLICATE HANDLING\n",
    "print(\"\\n5. DUPLICATE handling:\")\n",
    "# Create DataFrame with duplicates\n",
    "duplicate_df = pd.concat([employees, employees.iloc[[0, 1]]], ignore_index=True)\n",
    "print(\"DataFrame with duplicates:\")\n",
    "print(duplicate_df)\n",
    "\n",
    "# Remove duplicates\n",
    "no_duplicates = duplicate_df.drop_duplicates()\n",
    "print(\"\\nAfter removing duplicates:\")\n",
    "print(no_duplicates)\n",
    "\n",
    "# Keep first/last occurrence\n",
    "first_occurrence = duplicate_df.drop_duplicates(keep=\"first\")\n",
    "last_occurrence = duplicate_df.drop_duplicates(keep=\"last\")\n",
    "print(f\"\\nFirst occurrence: {len(first_occurrence)} rows\")\n",
    "print(f\"Last occurrence: {len(last_occurrence)} rows\")\n",
    "\n",
    "# 6. CHAINING OPERATIONS\n",
    "print(\"\\n6. METHOD CHAINING:\")\n",
    "result = (\n",
    "    employees.query(\"salary > 60000\")\n",
    "    .groupby(\"department\")\n",
    "    .agg({\"salary\": \"mean\", \"name\": \"count\"})\n",
    "    .rename(columns={\"name\": \"employee_count\"})\n",
    "    .sort_values(\"salary\", ascending=False)\n",
    ")\n",
    "print(\"Chained operations result:\")\n",
    "print(result)\n",
    "\n",
    "# 7. APPLY with custom functions\n",
    "print(\"\\n7. APPLY with custom functions:\")\n",
    "\n",
    "\n",
    "def categorize_salary(salary):\n",
    "    if salary >= 80000:\n",
    "        return \"High\"\n",
    "    elif salary >= 60000:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "\n",
    "employees[\"salary_category\"] = employees[\"salary\"].apply(categorize_salary)\n",
    "print(employees[[\"name\", \"salary\", \"salary_category\"]])\n",
    "\n",
    "# 8. VECTORIZED OPERATIONS\n",
    "print(\"\\n8. VECTORIZED operations:\")\n",
    "employees[\"bonus\"] = employees[\"salary\"] * 0.1  # 10% bonus\n",
    "employees[\"total_comp\"] = employees[\"salary\"] + employees[\"bonus\"]\n",
    "print(employees[[\"name\", \"salary\", \"bonus\", \"total_comp\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d81624",
   "metadata": {},
   "source": [
    "## 7. PERFORMANCE TIPS and BEST PRACTICES\n",
    "\n",
    "Optimization techniques for large DataFrames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541fb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PERFORMANCE TIPS and BEST PRACTICES ===\")\n",
    "\n",
    "# 1. DATATYPE OPTIMIZATION\n",
    "print(\"1. DATATYPE OPTIMIZATION:\")\n",
    "print(\"Original dtypes:\")\n",
    "print(employees.dtypes)\n",
    "\n",
    "# Optimize dtypes\n",
    "employees_optimized = employees.copy()\n",
    "employees_optimized[\"emp_id\"] = employees_optimized[\"emp_id\"].astype(\"category\")\n",
    "employees_optimized[\"department\"] = employees_optimized[\"department\"].astype(\"category\")\n",
    "employees_optimized[\"manager_id\"] = employees_optimized[\"manager_id\"].astype(\"category\")\n",
    "\n",
    "print(\"\\nOptimized dtypes:\")\n",
    "print(employees_optimized.dtypes)\n",
    "print(f\"Memory usage - Original: {employees.memory_usage(deep=True).sum()} bytes\")\n",
    "print(f\"Memory usage - Optimized: {employees_optimized.memory_usage(deep=True).sum()} bytes\")\n",
    "\n",
    "# 2. EFFICIENT FILTERING\n",
    "print(\"\\n2. EFFICIENT FILTERING:\")\n",
    "# Good: Use vectorized operations\n",
    "good_filter = employees[employees[\"salary\"] > 70000]\n",
    "\n",
    "# Better: Use query for complex conditions\n",
    "better_filter = employees.query(\"salary > 70000 and department == 'Engineering'\")\n",
    "\n",
    "# Best: Chain operations efficiently\n",
    "best_filter = employees.query(\"salary > 70000\").query(\"department == 'Engineering'\").sort_values(\"salary\", ascending=False)\n",
    "\n",
    "print(\"Filtered results:\")\n",
    "print(best_filter)\n",
    "\n",
    "# 3. AVOID ITERROWS() - Use vectorized operations instead\n",
    "print(\"\\n3. VECTORIZED vs ITERROWS:\")\n",
    "# BAD: iterrows() (slow)\n",
    "# for index, row in employees.iterrows():\n",
    "#     employees.loc[index, 'bonus'] = row['salary'] * 0.1\n",
    "\n",
    "# GOOD: Vectorized operations (fast)\n",
    "employees[\"bonus_vectorized\"] = employees[\"salary\"] * 0.1\n",
    "print(\"Vectorized bonus calculation:\")\n",
    "print(employees[[\"name\", \"salary\", \"bonus_vectorized\"]])\n",
    "\n",
    "# 4. USE LOC/ILOC EFFICIENTLY\n",
    "print(\"\\n4. EFFICIENT INDEXING:\")\n",
    "# Good: Use loc for label-based indexing\n",
    "subset = employees.loc[employees[\"salary\"] > 70000, [\"name\", \"salary\", \"department\"]]\n",
    "print(\"Using loc:\")\n",
    "print(subset)\n",
    "\n",
    "# 5. CHAINING vs INTERMEDIATE VARIABLES\n",
    "print(\"\\n5. METHOD CHAINING vs INTERMEDIATE VARIABLES:\")\n",
    "# Method chaining (memory efficient)\n",
    "chained_result = employees.query(\"salary > 60000\").groupby(\"department\").agg({\"salary\": \"mean\"}).round(2)\n",
    "\n",
    "# Intermediate variables (more readable but uses more memory)\n",
    "filtered = employees.query(\"salary > 60000\")\n",
    "grouped = filtered.groupby(\"department\")\n",
    "intermediate_result = grouped.agg({\"salary\": \"mean\"}).round(2)\n",
    "\n",
    "print(\"Chained result:\")\n",
    "print(chained_result)\n",
    "print(\"\\nIntermediate result:\")\n",
    "print(intermediate_result)\n",
    "\n",
    "# 6. COPY vs VIEW\n",
    "print(\"\\n6. COPY vs VIEW:\")\n",
    "# View (no memory copy)\n",
    "view = employees[[\"name\", \"salary\"]]\n",
    "print(f\"View memory usage: {view.memory_usage(deep=True).sum()} bytes\")\n",
    "\n",
    "# Copy (memory copy)\n",
    "copy = employees[[\"name\", \"salary\"]].copy()\n",
    "print(f\"Copy memory usage: {copy.memory_usage(deep=True).sum()} bytes\")\n",
    "\n",
    "# 7. USEFUL METHODS FOR LARGE DATASETS\n",
    "print(\"\\n7. USEFUL METHODS FOR LARGE DATASETS:\")\n",
    "print(\"DataFrame info:\")\n",
    "print(f\"Shape: {employees.shape}\")\n",
    "print(f\"Memory usage: {employees.memory_usage(deep=True).sum()} bytes\")\n",
    "print(f\"Columns: {list(employees.columns)}\")\n",
    "print(f\"Index type: {type(employees.index)}\")\n",
    "\n",
    "# 8. QUERY OPTIMIZATION\n",
    "print(\"\\n8. QUERY OPTIMIZATION TIPS:\")\n",
    "print(\"âœ“ Use .query() for complex conditions\")\n",
    "print(\"âœ“ Use .isin() instead of multiple OR conditions\")\n",
    "print(\"âœ“ Use .between() for range queries\")\n",
    "print(\"âœ“ Use categorical dtypes for repeated string values\")\n",
    "print(\"âœ“ Use .loc[] and .iloc[] for specific row/column selection\")\n",
    "print(\"âœ“ Avoid .apply() when vectorized operations are available\")\n",
    "print(\"âœ“ Use method chaining to reduce intermediate variables\")\n",
    "print(\"âœ“ Consider using .eval() for complex expressions on large DataFrames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29179630",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_data: dict[str, list] = {\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Frank\", \"George\", \"Helen\", \"Ivy\", \"Jack\"],\n",
    "    \"age\": [25, 30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
    "    \"city\": [\n",
    "        \"New York\",\n",
    "        \"Los Angeles\",\n",
    "        \"Chicago\",\n",
    "        \"Houston\",\n",
    "        \"Phoenix\",\n",
    "        \"Philadelphia\",\n",
    "        \"San Antonio\",\n",
    "        \"San Diego\",\n",
    "        \"Dallas\",\n",
    "        \"San Jose\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "df_person = pd.DataFrame(person_data)\n",
    "\n",
    "df_person.head()\n",
    "\n",
    "df_person.tail()\n",
    "\n",
    "df_person.info()\n",
    "\n",
    "df_person.describe()\n",
    "\n",
    "print(df_person)\n",
    "\n",
    "print(df_person.dtypes)\n",
    "\n",
    "print(df_person.columns)\n",
    "\n",
    "print(df_person.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ecdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1.1 Creating DataFrame from LIST of dictionaries\n",
    "print(\"ðŸ”¹ Creating DataFrame from LIST of dictionaries:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# List of dictionaries - most common way\n",
    "person_data_v2: list[dict[str, list]] = [\n",
    "    {\"name\": \"Alice\", \"age\": 25, \"city\": \"New York\"},\n",
    "    {\"name\": \"Bob\", \"age\": 30, \"city\": \"Los Angeles\"},\n",
    "    {\"name\": \"Charlie\", \"age\": 35, \"city\": \"Chicago\"},\n",
    "    {\"name\": \"David\", \"age\": 40, \"city\": \"Houston\"},\n",
    "    {\"name\": \"Eve\", \"age\": 45, \"city\": \"Phoenix\"},\n",
    "    {\"name\": \"Frank\", \"age\": 50, \"city\": \"Philadelphia\"},\n",
    "    {\"name\": \"George\", \"age\": 55, \"city\": \"San Antonio\"},\n",
    "    {\"name\": \"Helen\", \"age\": 60, \"city\": \"San Diego\"},\n",
    "    {\"name\": \"Ivy\", \"age\": 65, \"city\": \"Dallas\"},\n",
    "    {\"name\": \"Jack\", \"age\": 70, \"city\": \"San Jose\"},\n",
    "]\n",
    "\n",
    "df_person_v2 = pd.DataFrame(person_data_v2)\n",
    "\n",
    "print(df_person_v2)\n",
    "\n",
    "print(df_person_v2.shape)\n",
    "\n",
    "print(df_person_v2.dtypes)\n",
    "\n",
    "print(df_person_v2.columns)\n",
    "\n",
    "print(df_person_v2.head())\n",
    "\n",
    "print(df_person_v2.tail())\n",
    "\n",
    "print(df_person_v2.info())\n",
    "\n",
    "print(df_person_v2.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce412ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample customer data using dictionary\n",
    "customer_data = {\n",
    "    \"customer_id\": [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008],\n",
    "    \"name\": [\n",
    "        \"Alice Smith\",\n",
    "        \"Bob Johnson\",\n",
    "        \"Charlie Brown\",\n",
    "        \"Diana Prince\",\n",
    "        \"Eve Wilson\",\n",
    "        \"Frank Miller\",\n",
    "        \"Grace Lee\",\n",
    "        \"Henry Davis\",\n",
    "    ],\n",
    "    \"age\": [28, 35, 42, 29, 38, 45, 31, 52],\n",
    "    \"email\": [\n",
    "        \"alice@email.com\",\n",
    "        \"bob@email.com\",\n",
    "        \"charlie@email.com\",\n",
    "        \"diana@email.com\",\n",
    "        \"eve@email.com\",\n",
    "        None,\n",
    "        \"grace@email.com\",\n",
    "        \"henry@email.com\",\n",
    "    ],\n",
    "    \"total_purchases\": [15, 8, 23, 5, 31, 12, 19, 7],\n",
    "    \"total_spent\": [1250.50, 890.25, 3420.80, 567.00, 4890.15, 1678.90, 2345.60, 823.40],\n",
    "    \"member_since\": [\n",
    "        \"2020-03-15\",\n",
    "        \"2019-08-22\",\n",
    "        \"2018-11-30\",\n",
    "        \"2021-05-10\",\n",
    "        \"2017-02-18\",\n",
    "        \"2020-09-05\",\n",
    "        \"2019-12-20\",\n",
    "        \"2021-01-08\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "df_customers = pd.DataFrame(customer_data)\n",
    "\n",
    "result = df_customers.age > 30\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13bf8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "selected_customers = df_customers.loc[[False, True, True, False, True, True, True, True]]\n",
    "\n",
    "customers_over_30 = df_customers.loc[df_customers.age > 30]\n",
    "\n",
    "customers_name_age_over_30 = df_customers.loc[df_customers.age > 30, [\"name\", \"age\"]]\n",
    "\n",
    "\n",
    "display(HTML(customers_name_age_over_30.to_html()))\n",
    "\n",
    "\n",
    "print(selected_customers)\n",
    "\n",
    "print(customers_over_30)\n",
    "\n",
    "print(customers_name_age_over_30)\n",
    "\n",
    "df_customers.loc[df_customers.age > 30, \"email\"] = \"Unknown\"\n",
    "\n",
    "print(df_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ea13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1 = {\n",
    "    \"name\": [\n",
    "        \"Alice\",\n",
    "        \"Bob\",\n",
    "        \"Charlie\",\n",
    "        \"Diana\",\n",
    "        \"Eve\",\n",
    "        \"Frank\",\n",
    "        \"Grace\",\n",
    "        \"Henry\",\n",
    "    ],\n",
    "    \"age\": [\n",
    "        28,\n",
    "        35,\n",
    "        42,\n",
    "        29,\n",
    "        38,\n",
    "        45,\n",
    "        31,\n",
    "        52,\n",
    "    ],\n",
    "    \"city\": [\n",
    "        \"New York\",\n",
    "        \"Los Angeles\",\n",
    "        \"Chicago\",\n",
    "        \"Houston\",\n",
    "        \"Phoenix\",\n",
    "        \"Philadelphia\",\n",
    "        \"San Antonio\",\n",
    "        \"San Diego\",\n",
    "    ],\n",
    "    \"email\": [\n",
    "        \"alice@email.com\",\n",
    "        \"bob@email.com\",\n",
    "        \"charlie@email.com\",\n",
    "        \"diana@email.com\",\n",
    "        \"eve@email.com\",\n",
    "        \"frank@email.com\",\n",
    "        \"grace@email.com\",\n",
    "        \"henry@email.com\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "df_customers_v1 = pd.DataFrame(data_v1)\n",
    "\n",
    "df_customers_v1_over_30 = df_customers_v1[df_customers_v1.age > 30]\n",
    "\n",
    "print(df_customers_v1)\n",
    "\n",
    "print()\n",
    "\n",
    "print(df_customers_v1_over_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b7a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”¹ Creating DataFrame from DICTIONARY of lists:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Dictionary of lists - efficient for large datasets\n",
    "data_v2 = [\n",
    "    {\"name\": \"Alice\", \"age\": 25, \"city\": \"New York\"},\n",
    "    {\"name\": \"Bob\", \"age\": 30, \"city\": \"Los Angeles\"},\n",
    "    {\"name\": \"Charlie\", \"age\": 35, \"city\": \"Chicago\"},\n",
    "    {\"name\": \"Diana\", \"age\": 40, \"city\": \"Houston\"},\n",
    "    {\"name\": \"Eve\", \"age\": 45, \"city\": \"Phoenix\"},\n",
    "    {\"name\": \"Frank\", \"age\": 50, \"city\": \"Philadelphia\"},\n",
    "]\n",
    "\n",
    "df_customers_v2 = pd.DataFrame(data_v2)\n",
    "\n",
    "print(df_customers_v2)\n",
    "\n",
    "df_customers_v2_over_30 = df_customers_v2[df_customers_v2.age > 30]\n",
    "\n",
    "print()\n",
    "\n",
    "print(df_customers_v2_over_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19196e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v3 = [\n",
    "    [\n",
    "        \"Alice\",\n",
    "        25,\n",
    "        \"New York\",\n",
    "        \"alice@email.com\",\n",
    "        15,\n",
    "        1250.50,\n",
    "    ],\n",
    "    [\n",
    "        \"Bob\",\n",
    "        30,\n",
    "        \"Los Angeles\",\n",
    "        \"bob@email.com\",\n",
    "        8,\n",
    "        890.25,\n",
    "    ],\n",
    "    [\n",
    "        \"Charlie\",\n",
    "        35,\n",
    "        \"Chicago\",\n",
    "        \"charlie@email.com\",\n",
    "        23,\n",
    "        3420.80,\n",
    "    ],\n",
    "    [\n",
    "        \"Diana\",\n",
    "        40,\n",
    "        \"Houston\",\n",
    "        \"diana@email.com\",\n",
    "        5,\n",
    "        567.00,\n",
    "    ],\n",
    "]\n",
    "\n",
    "df_customers_v3 = pd.DataFrame(data_v3, columns=[\"name\", \"age\", \"city\", \"email\", \"total_purchase\", \"total_spent\"])\n",
    "\n",
    "print(df_customers_v3)\n",
    "\n",
    "df_customers_v3_over_30 = df_customers_v3[df_customers_v3.age > 30]\n",
    "\n",
    "print()\n",
    "\n",
    "print(df_customers_v3_over_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b706328b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c84e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”¹ Creating DataFrame from TUPLE of tuples:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Tuple of tuples - immutable data structure\n",
    "data_v4 = (\n",
    "    (\n",
    "        \"Alice\",\n",
    "        25,\n",
    "        \"New York\",\n",
    "        \"alice@email.com\",\n",
    "        15,\n",
    "        1250.50,\n",
    "    ),\n",
    "    (\n",
    "        \"Bob\",\n",
    "        30,\n",
    "        \"Los Angeles\",\n",
    "        \"bob@email.com\",\n",
    "        8,\n",
    "        890.25,\n",
    "    ),\n",
    "    (\n",
    "        \"Charlie\",\n",
    "        35,\n",
    "        \"Chicago\",\n",
    "        \"charlie@email.com\",\n",
    "        23,\n",
    "        3420.80,\n",
    "    ),\n",
    "    (\n",
    "        \"Diana\",\n",
    "        40,\n",
    "        \"Houston\",\n",
    "        \"diana@email.com\",\n",
    "        5,\n",
    "        567.00,\n",
    "    ),\n",
    ")\n",
    "\n",
    "df_customers_v4 = pd.DataFrame(data_v4, columns=[\"name\", \"age\", \"city\", \"email\", \"total_purchase\", \"total_spent\"])\n",
    "\n",
    "print(df_customers_v4)\n",
    "\n",
    "df_customers_v4_over_30 = df_customers_v4[df_customers_v4.age > 30]\n",
    "\n",
    "print()\n",
    "\n",
    "print(df_customers_v4_over_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "print(\"ðŸ”¹ Creating DataFrame using SET operations:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Using set comprehensions and operations\n",
    "departments = {\"Engineering\", \"Marketing\", \"Sales\", \"HR\", \"Finance\"}\n",
    "employees_per_dept = {dept: random.randint(5, 20) for dept in departments}\n",
    "budget_per_dept = {dept: random.randint(10000, 50000) for dept in departments}\n",
    "\n",
    "dept_data = []\n",
    "for dept in departments:\n",
    "    dept_data.append(\n",
    "        {\n",
    "            \"department\": dept,\n",
    "            \"employee_count\": employees_per_dept[dept],\n",
    "            \"budget\": budget_per_dept[dept],\n",
    "            \"budget_per_employee\": budget_per_dept[dept] / employees_per_dept[dept],\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_from_set = pd.DataFrame(dept_data)\n",
    "\n",
    "print(departments)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(df_from_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97813962",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”¹ Adding and Modifying Columns:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Tuple of tuples - immutable data structure\n",
    "data_v5 = (\n",
    "    (\"John\", \"Doe\", 32, \"Engineer\", 85000),\n",
    "    (\"Jane\", \"Smith\", 28, \"Designer\", 72000),\n",
    "    (\"Mike\", \"Johnson\", 35, \"Manager\", 95000),\n",
    "    (\"Sarah\", \"Wilson\", 29, \"Analyst\", 68000),\n",
    "    (\"Tom\", \"Brown\", 31, \"Developer\", 78000),\n",
    ")\n",
    "\n",
    "df_person_v3 = pd.DataFrame(data_v5, columns=[\"first_name\", \"last_name\", \"age\", \"job_title\", \"salary\"])\n",
    "\n",
    "# Add new columns\n",
    "df_person_v3[\"full_name\"] = df_person_v3[\"first_name\"] + \" \" + df_person_v3[\"last_name\"]\n",
    "df_person_v3[\"salary_category\"] = df_person_v3[\"salary\"].apply(lambda x: \"High\" if x > 8000 else \"Medium\" if x > 7000 else \"Low\")\n",
    "df_person_v3[\"years_until_retirement\"] = 65 - df_person_v3[\"age\"]\n",
    "\n",
    "print(df_person_v3)\n",
    "\n",
    "df_person_v3[\"salary\"] = df_person_v3[\"salary\"] * 1.1  # 10% raise\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(df_person_v3[[\"full_name\", \"salary\", \"salary_category\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1 Advanced filtering with multiple conditions\n",
    "print(\"ðŸ”¹ Advanced Filtering Operations:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Create a larger dataset for better filtering examples\n",
    "np.random.seed(42)\n",
    "n_employees = 20\n",
    "\n",
    "# Generate employee data using different data structures\n",
    "first_names = [\n",
    "    \"Alice\",\n",
    "    \"Bob\",\n",
    "    \"Charlie\",\n",
    "    \"Diana\",\n",
    "    \"Eve\",\n",
    "    \"Frank\",\n",
    "    \"Grace\",\n",
    "    \"Henry\",\n",
    "    \"Ivy\",\n",
    "    \"Jack\",\n",
    "    \"Kate\",\n",
    "    \"Liam\",\n",
    "    \"Maya\",\n",
    "    \"Noah\",\n",
    "    \"Olivia\",\n",
    "    \"Paul\",\n",
    "    \"Quinn\",\n",
    "    \"Ruby\",\n",
    "    \"Sam\",\n",
    "    \"Tina\",\n",
    "]\n",
    "\n",
    "departments = [\"Engineering\", \"Marketing\", \"Sales\", \"HR\", \"Finance\"]\n",
    "cities = [\"New York\", \"London\", \"Tokyo\", \"Paris\", \"Berlin\", \"Sydney\"]\n",
    "\n",
    "# Create comprehensive employee data\n",
    "employee_data = []\n",
    "for i in range(n_employees):\n",
    "    employee_data.append(\n",
    "        {\n",
    "            \"employee_id\": f\"EMP{i + 1:03d}\",\n",
    "            \"name\": first_names[i],\n",
    "            \"age\": random.randint(22, 65),\n",
    "            \"department\": random.choice(departments),\n",
    "            \"city\": random.choice(cities),\n",
    "            \"salary\": random.randint(40000, 120000),\n",
    "            \"years_experience\": random.randint(0, 20),\n",
    "            \"performance_score\": round(random.uniform(1.0, 5.0), 1),\n",
    "            \"is_manager\": random.choice([True, False]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_employees = pd.DataFrame(employee_data)\n",
    "\n",
    "print(\"Employee Dataset:\")\n",
    "print(df_employees.head(10))\n",
    "print(f\"Total employees: {len(df_employees)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f38e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 Complex filtering with multiple conditions\n",
    "print(\"ðŸ”¹ Complex Filtering Examples:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Filter 1: High performers in Engineering\n",
    "high_performers_eng_v1 = df_employees[(df_employees[\"department\"] == \"Engineering\") & (df_employees[\"performance_score\"] >= 4.0)]\n",
    "print(\"High performers in Engineering:\")\n",
    "print(high_performers_eng_v1[[\"name\", \"department\", \"performance_score\", \"salary\"]])\n",
    "print()\n",
    "\n",
    "high_performers_eng_v2 = df_employees[\n",
    "    df_employees[\"department\"].isin([\"Engineering\", \"Marketing\"]) & (df_employees[\"performance_score\"] >= 4.0)\n",
    "]\n",
    "print(\"High performers in Engineering and Marketing:\")\n",
    "print(high_performers_eng_v2[[\"name\", \"department\", \"performance_score\", \"salary\"]])\n",
    "print()\n",
    "\n",
    "high_performers_eng_v3 = df_employees.query(\"department in ['Engineering', 'Marketing'] and performance_score >= 4.0\")\n",
    "print(\"High performers in Engineering and Marketing:\")\n",
    "print(high_performers_eng_v3[[\"name\", \"department\", \"performance_score\", \"salary\"]])\n",
    "print()\n",
    "\n",
    "high_performers_eng_v4 = df_employees.loc[\n",
    "    (df_employees[\"department\"] == \"Engineering\") & (df_employees[\"performance_score\"] >= 4.0)\n",
    "]\n",
    "print(\"High performers in Engineering:\")\n",
    "print(high_performers_eng_v4[[\"name\", \"department\", \"performance_score\", \"salary\"]])\n",
    "print()\n",
    "\n",
    "hight_performers_eng_v4_1 = df_employees.loc[\n",
    "    df_employees[\"department\"].isin([\"Engineering\", \"Marketing\"]) & df_employees[\"performance_score\"] >= 4.0\n",
    "]\n",
    "print(\"High performers in Engineering and Marketing:\")\n",
    "print(hight_performers_eng_v4_1[[\"name\", \"department\", \"performance_score\", \"salary\"]])\n",
    "print()\n",
    "\n",
    "high_performers_eng_v5 = df_employees[\n",
    "    df_employees.apply(lambda row: row[\"department\"] in [\"Engineering\", \"Marketing\"] and row[\"performance_score\"] >= 4.0, axis=1)\n",
    "]\n",
    "print(\"High performers in Engineering and Marketing:\")\n",
    "print(high_performers_eng_v5[[\"name\", \"department\", \"performance_score\", \"salary\"]])\n",
    "print()\n",
    "\n",
    "high_performers_eng_v6 = df_employees.query(\"department == 'Engineering'\").query(\"performance_score >= 4.0\")\n",
    "high_performers_eng_v7 = df_employees.query(\"department in ['Engineering', 'Marketing']\").query(\"performance_score >= 4.0\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(high_performers_eng_v6)\n",
    "print(\"-\" * 50)\n",
    "print(high_performers_eng_v7)\n",
    "\n",
    "\n",
    "# Filter 2:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
